"""
Proactive monitoring agent that continuously checks for issues.

Monitors key metrics and alerts users before they ask.
"""
from __future__ import annotations

import asyncio
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

from backend.intelligence.anomaly import (
    Anomaly,
    AnomalyDetector,
    TimeSeriesPoint,
    get_anomaly_detector
)
from backend.tools.mcp_client import MCPClient
from backend.utils.logger import get_logger

logger = get_logger(__name__)


@dataclass
class MonitoringTarget:
    """Configuration for a metric to monitor."""

    name: str
    query: str  # PromQL or LogQL query
    datasource_uid: str
    query_type: str  # "prometheus" or "loki"
    check_interval: int  # seconds
    detection_methods: List[str]
    severity_threshold: str  # Minimum severity to alert on
    enabled: bool = True
    last_check: Optional[datetime] = None


@dataclass
class ProactiveAlert:
    """Alert generated by proactive monitoring."""

    timestamp: datetime
    target: MonitoringTarget
    anomalies: List[Anomaly]
    investigation: Optional[str] = None  # AI-generated investigation
    severity: str = "medium"
    acknowledged: bool = False


class ProactiveMonitor:
    """
    Continuously monitors metrics and alerts on anomalies.

    Runs in the background and uses the agent to investigate issues.
    """

    def __init__(self, mcp_client: MCPClient):
        self.mcp_client = mcp_client
        self.anomaly_detector = get_anomaly_detector()
        self.targets: Dict[str, MonitoringTarget] = {}
        self.alerts: List[ProactiveAlert] = []
        self.running = False
        self._task: Optional[asyncio.Task] = None

        # Callbacks for notifications
        self.alert_callbacks: List[callable] = []

    def add_target(self, target: MonitoringTarget):
        """Add a monitoring target."""
        self.targets[target.name] = target
        logger.info(f"Added monitoring target: {target.name}")

    def remove_target(self, name: str):
        """Remove a monitoring target."""
        if name in self.targets:
            del self.targets[name]
            logger.info(f"Removed monitoring target: {name}")

    def add_alert_callback(self, callback: callable):
        """Add callback to be called when alerts are generated."""
        self.alert_callbacks.append(callback)

    async def start(self):
        """Start the proactive monitoring loop."""
        if self.running:
            logger.warning("Proactive monitor already running")
            return

        self.running = True
        self._task = asyncio.create_task(self._monitoring_loop())
        logger.info("Proactive monitor started")

    async def stop(self):
        """Stop the proactive monitoring loop."""
        self.running = False
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:
                pass
        logger.info("Proactive monitor stopped")

    async def _monitoring_loop(self):
        """Main monitoring loop."""
        logger.info("Starting proactive monitoring loop")

        while self.running:
            try:
                # Check each target
                for target in list(self.targets.values()):
                    if not target.enabled:
                        continue

                    # Check if it's time to check this target
                    if target.last_check is not None:
                        time_since_check = (datetime.utcnow() - target.last_check).total_seconds()
                        if time_since_check < target.check_interval:
                            continue

                    # Check the target
                    await self._check_target(target)

                # Sleep before next iteration
                await asyncio.sleep(10)  # Check every 10 seconds

            except Exception as e:
                logger.error(f"Error in monitoring loop: {e}", exc_info=True)
                await asyncio.sleep(30)  # Back off on error

    async def _check_target(self, target: MonitoringTarget):
        """Check a single monitoring target for anomalies."""
        logger.debug(f"Checking target: {target.name}")

        try:
            # Fetch data from Grafana
            data = await self._fetch_metric_data(target)

            if not data:
                logger.warning(f"No data returned for target: {target.name}")
                target.last_check = datetime.utcnow()
                return

            # Convert to TimeSeriesPoints
            time_series = self._parse_time_series(data, target.query_type)

            if len(time_series) < 3:
                logger.debug(f"Insufficient data points for {target.name}: {len(time_series)}")
                target.last_check = datetime.utcnow()
                return

            # Detect anomalies
            anomalies = self.anomaly_detector.detect_anomalies(
                data=time_series,
                metric_name=target.name,
                methods=target.detection_methods
            )

            # Filter by severity threshold
            severity_levels = {"low": 0, "medium": 1, "high": 2, "critical": 3}
            threshold_level = severity_levels.get(target.severity_threshold, 1)

            significant_anomalies = [
                a for a in anomalies
                if severity_levels.get(a.severity, 0) >= threshold_level
            ]

            if significant_anomalies:
                logger.warning(
                    f"Detected {len(significant_anomalies)} significant anomalies in {target.name}"
                )
                await self._handle_anomalies(target, significant_anomalies)

            target.last_check = datetime.utcnow()

        except Exception as e:
            logger.error(f"Error checking target {target.name}: {e}", exc_info=True)
            target.last_check = datetime.utcnow()

    async def _fetch_metric_data(self, target: MonitoringTarget) -> Any:
        """Fetch metric data from Grafana."""
        try:
            if target.query_type == "prometheus":
                # Query Prometheus for range data (last hour)
                result = await self.mcp_client.invoke_tool(
                    "query_prometheus",
                    {
                        "datasource_uid": target.datasource_uid,
                        "query": target.query,
                        "start": (datetime.utcnow() - timedelta(hours=1)).isoformat(),
                        "end": datetime.utcnow().isoformat(),
                        "step": "60s"
                    }
                )
                return result

            elif target.query_type == "loki":
                # Query Loki for logs
                result = await self.mcp_client.invoke_tool(
                    "query_loki_logs",
                    {
                        "datasource_uid": target.datasource_uid,
                        "query": target.query,
                        "start": (datetime.utcnow() - timedelta(hours=1)).isoformat(),
                        "end": datetime.utcnow().isoformat(),
                        "limit": 1000
                    }
                )
                return result

        except Exception as e:
            logger.error(f"Error fetching data for {target.name}: {e}")
            return None

    def _parse_time_series(self, data: Any, query_type: str) -> List[TimeSeriesPoint]:
        """Parse MCP response into TimeSeriesPoints."""
        time_series = []

        try:
            if query_type == "prometheus":
                # Handle Prometheus matrix response
                if isinstance(data, list) and data:
                    for item in data:
                        if isinstance(item, dict) and "text" in item:
                            # MCP content format
                            # Would need to parse the text
                            pass
                        elif isinstance(item, dict) and "values" in item:
                            # Direct Prometheus format
                            for timestamp, value in item["values"]:
                                try:
                                    time_series.append(TimeSeriesPoint(
                                        timestamp=datetime.fromtimestamp(float(timestamp)),
                                        value=float(value)
                                    ))
                                except (ValueError, TypeError):
                                    continue

            elif query_type == "loki":
                # Handle Loki response - count log entries
                if isinstance(data, list):
                    # Count log entries per time bucket
                    # This is simplified - would need proper bucketing
                    pass

        except Exception as e:
            logger.error(f"Error parsing time series: {e}", exc_info=True)

        return time_series

    async def _handle_anomalies(
        self,
        target: MonitoringTarget,
        anomalies: List[Anomaly]
    ):
        """Handle detected anomalies - create alert and notify."""
        # Determine overall severity (highest from anomalies)
        severity_order = {"low": 0, "medium": 1, "high": 2, "critical": 3}
        max_severity = max(
            anomalies,
            key=lambda a: severity_order.get(a.severity, 0)
        ).severity

        # Create alert
        alert = ProactiveAlert(
            timestamp=datetime.utcnow(),
            target=target,
            anomalies=anomalies,
            severity=max_severity
        )

        # Add to alert list
        self.alerts.append(alert)

        # Keep only last 100 alerts
        if len(self.alerts) > 100:
            self.alerts = self.alerts[-100:]

        # Notify via callbacks
        for callback in self.alert_callbacks:
            try:
                await callback(alert)
            except Exception as e:
                logger.error(f"Error in alert callback: {e}", exc_info=True)

        logger.warning(
            f"Generated {severity} alert for {target.name}: "
            f"{len(anomalies)} anomalies detected"
        )

    def get_recent_alerts(
        self,
        minutes: int = 60,
        min_severity: str = "low"
    ) -> List[ProactiveAlert]:
        """Get recent alerts."""
        cutoff = datetime.utcnow() - timedelta(minutes=minutes)
        severity_order = {"low": 0, "medium": 1, "high": 2, "critical": 3}
        threshold = severity_order.get(min_severity, 0)

        return [
            alert for alert in self.alerts
            if alert.timestamp > cutoff
            and severity_order.get(alert.severity, 0) >= threshold
        ]

    def acknowledge_alert(self, alert: ProactiveAlert):
        """Mark alert as acknowledged."""
        alert.acknowledged = True
        logger.info(f"Alert acknowledged: {alert.target.name}")

    def get_monitoring_status(self) -> Dict[str, Any]:
        """Get current monitoring status."""
        return {
            "running": self.running,
            "targets_count": len(self.targets),
            "enabled_targets": sum(1 for t in self.targets.values() if t.enabled),
            "total_alerts": len(self.alerts),
            "recent_alerts": len(self.get_recent_alerts(minutes=60)),
            "critical_alerts": len([
                a for a in self.alerts
                if a.severity == "critical" and not a.acknowledged
            ])
        }


# Global singleton
_proactive_monitor: Optional[ProactiveMonitor] = None


def get_proactive_monitor(mcp_client: MCPClient = None) -> ProactiveMonitor:
    """Get or create global proactive monitor."""
    global _proactive_monitor
    if _proactive_monitor is None:
        if mcp_client is None:
            raise ValueError("MCP client required for first initialization")
        _proactive_monitor = ProactiveMonitor(mcp_client)
        logger.info("Initialized proactive monitor")
    return _proactive_monitor


def create_default_targets() -> List[MonitoringTarget]:
    """Create sensible default monitoring targets."""
    return [
        MonitoringTarget(
            name="error_rate",
            query='rate(http_requests_total{status=~"5.."}[5m])',
            datasource_uid="prometheus",  # Would need actual UID
            query_type="prometheus",
            check_interval=300,  # 5 minutes
            detection_methods=["zscore", "rate_change"],
            severity_threshold="medium"
        ),
        MonitoringTarget(
            name="response_time_p95",
            query='histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))',
            datasource_uid="prometheus",
            query_type="prometheus",
            check_interval=300,
            detection_methods=["zscore", "iqr"],
            severity_threshold="medium"
        ),
        MonitoringTarget(
            name="cpu_usage",
            query='100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)',
            datasource_uid="prometheus",
            query_type="prometheus",
            check_interval=180,  # 3 minutes
            detection_methods=["zscore", "iqr"],
            severity_threshold="high"
        ),
        MonitoringTarget(
            name="memory_usage",
            query='(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100',
            datasource_uid="prometheus",
            query_type="prometheus",
            check_interval=300,
            detection_methods=["zscore"],
            severity_threshold="high"
        )
    ]
